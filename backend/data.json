[
    {
        "position": [
            [
                0.19394618834080718,
                0.4429477020602219
            ],
            [
                0.8139013452914798,
                0.4429477020602219
            ],
            [
                0.19394618834080718,
                0.6632329635499208
            ],
            [
                0.8139013452914798,
                0.6632329635499208
            ]
        ],
        "score": 1,
        "text": "<table>\n<thead>\n<tr>\n<td>\n      因子项\n     </td>\n<td>\n      实验组\n     </td>\n<td>\n      正常对照组\n     </td>\n<td>\n      t\n     </td>\n<td>\n      P\n     </td>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n      Hs\n     </td>\n<td>\n      56.91±9.70\n     </td>\n<td>\n      42. 78 ±6. 40\n     </td>\n<td>\n      8. 101\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      D\n     </td>\n<td>\n      61.91 ±12.03\n     </td>\n<td>\n      39. 20 ±9. 36\n     </td>\n<td>\n      9. 746\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Hy\n     </td>\n<td>\n      63.04 ±10.84\n     </td>\n<td>\n      44. 63 ±8. 48\n     </td>\n<td>\n      8. 869\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Pd\n     </td>\n<td>\n      60.20 ±12.31\n     </td>\n<td>\n      47. 63 ±9. 35\n     </td>\n<td>\n      5. 309\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Mf\n     </td>\n<td>\n      52.41 ±11.60\n     </td>\n<td>\n      44.41 ±11.26\n     </td>\n<td>\n      3. 254\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Pa\n     </td>\n<td>\n      57.72 ±11.57\n     </td>\n<td>\n      42. 95 ±8. 45\n     </td>\n<td>\n      6. 727\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Pt\n     </td>\n<td>\n      59.43 ±11.55\n     </td>\n<td>\n      40. 90 ±9. 29\n     </td>\n<td>\n      8.180\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Sc\n     </td>\n<td>\n      55.48 ±11.41\n     </td>\n<td>\n      42.32±10.01\n     </td>\n<td>\n      5. 689\n     </td>\n<td>\n      0. 00\n     </td>\n</tr>\n<tr>\n<td>\n      Ma\n     </td>\n<td>\n      51.39±10.17\n     </td>\n<td>\n      49.63 ±8.81\n     </td>\n<td>\n      0. 856\n     </td>\n<td>\n      0. 42\n     </td>\n</tr>\n<tr>\n<td>\n      Si\n     </td>\n<td>\n      49.67±13.05\n     </td>\n<td>\n      40.22±12.16\n     </td>\n<td>\n      3.483\n     </td>\n<td>\n      0.00\n     </td>\n</tr>\n</tbody>\n</table>",
        "type": "table"
    },
    {
        "position": [
            [
                0.4080717488789238,
                0.13153724247226625
            ],
            [
                0.5952914798206278,
                0.13153724247226625
            ],
            [
                0.6052914798206278,
                0.1621394611727417
            ],
            [
                0.4080717488789238,
                0.1621394611727417
            ]
        ],
        "score": 0.6753816604614258,
        "text": "y=\\alpha x^{3}+b x^{2}+c x+d",
        "type": "formula"
    },
    {
        "position": [
            [
                0.31390134529147984,
                0.18462757527733756
            ],
            [
                0.6917040358744395,
                0.18462757527733756
            ],
            [
                0.7017040358744395,
                0.22077654516640255
            ],
            [
                0.31390134529147984,
                0.22077654516640255
            ]
        ],
        "score": 0.7953352928161621,
        "text": "J(a,b,c,d)=\\sum_{i=0}^{n}(y_{i}-(a x_{i}^{3}+b x_{i}^{2}+c x_{i}+d))^{2}",
        "type": "formula"
    },
    {
        "position": [
            [
                0.39798206278026904,
                0.7725832012678289
            ],
            [
                0.5975336322869955,
                0.7725832012678289
            ],
            [
                0.6075336322869955,
                0.8150713153724247
            ],
            [
                0.39798206278026904,
                0.8150713153724247
            ]
        ],
        "score": 0.3747934103012085,
        "text": "\\mid X\\mid_{F}=\\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}x_{\\bar{\\nu}}^{\\ 2}}",
        "type": "formula"
    },
    {
        "position": [
            [
                0.18721973094170405,
                0.08874801901743265
            ],
            [
                0.8497757847533632,
                0.08874801901743265
            ],
            [
                0.8597757847533632,
                0.1122187004754358
            ],
            [
                0.18721973094170405,
                0.10221870047543581
            ]
        ],
        "score": 0.9391019940376282,
        "text": "最小二乘法是一种用于拟合数据和估计参数的数学方法，通常用于线性回归分析和曲线",
        "type": "text"
    },
    {
        "position": [
            [
                0.15022421524663676,
                0.10697305863708399
            ],
            [
                0.5269058295964125,
                0.10697305863708399
            ],
            [
                0.5369058295964125,
                0.13044374009508716
            ],
            [
                0.15022421524663676,
                0.12044374009508717
            ]
        ],
        "score": 0.9141294360160828,
        "text": "拟合。这里使用最小二乘法拟合一个二次多项式：",
        "type": "text"
    },
    {
        "position": [
            [
                0.1860986547085202,
                0.1624405705229794
            ],
            [
                0.6322869955156951,
                0.1624405705229794
            ],
            [
                0.6422869955156951,
                0.18591125198098257
            ],
            [
                0.1860986547085202,
                0.17591125198098256
            ]
        ],
        "score": 0.9354431629180908,
        "text": "定义一个目标函数，通常为观测数据点的残差平方和，即",
        "type": "text"
    },
    {
        "position": [
            [
                0.18721973094170405,
                0.21870047543581617
            ],
            [
                0.8497757847533632,
                0.21870047543581617
            ],
            [
                0.8597757847533632,
                0.24217115689381935
            ],
            [
                0.18721973094170405,
                0.23217115689381934
            ]
        ],
        "score": 0.9469267129898071,
        "text": "通过对目标函数求偏导数，并令它们等于零，可以求解出最小二乘估计值，便可得到最",
        "type": "text"
    },
    {
        "position": [
            [
                0.15358744394618834,
                0.23771790808240886
            ],
            [
                0.3217488789237668,
                0.23771790808240886
            ],
            [
                0.3317488789237668,
                0.2611885895404121
            ],
            [
                0.15358744394618834,
                0.25118858954041207
            ]
        ],
        "score": 0.9580246210098267,
        "text": "佳的三次多项式模型。",
        "type": "text"
    },
    {
        "position": [
            [
                0.18721973094170405,
                0.2559429477020602
            ],
            [
                0.8497757847533632,
                0.2559429477020602
            ],
            [
                0.8597757847533632,
                0.2794136291600634
            ],
            [
                0.18721973094170405,
                0.2694136291600634
            ]
        ],
        "score": 0.9465410113334656,
        "text": "主成分分析（PCA）和线性判别分析（LDA）是两种常用的降维技术，利用线性变换将高",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.27258320126782887
            ],
            [
                0.8486547085201793,
                0.27258320126782887
            ],
            [
                0.8586547085201793,
                0.2968462757527734
            ],
            [
                0.15134529147982062,
                0.2868462757527734
            ]
        ],
        "score": 0.9261645078659058,
        "text": "维空间映射到低维空间，用于处理高维数据。PCA是一种无监督学习的线性降维方法。它通",
        "type": "text"
    },
    {
        "position": [
            [
                0.15022421524663676,
                0.29239302694136293
            ],
            [
                0.8486547085201793,
                0.29239302694136293
            ],
            [
                0.8586547085201793,
                0.3158637083993661
            ],
            [
                0.15022421524663676,
                0.3058637083993661
            ]
        ],
        "score": 0.9643110036849976,
        "text": "过计算数据中的主成分来提取数据的内在结构，并将高维空间映射到低维空间，以保留尽可",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.3114104595879556
            ],
            [
                0.8497757847533632,
                0.3114104595879556
            ],
            [
                0.8597757847533632,
                0.3348811410459588
            ],
            [
                0.15134529147982062,
                0.3248811410459588
            ]
        ],
        "score": 0.9351330399513245,
        "text": "能多的原始数据信息。LDA是一种监督学习的线性降维方法。它通过最大限度地区分不同类",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.3304278922345483
            ],
            [
                0.5179372197309418,
                0.3304278922345483
            ],
            [
                0.5279372197309418,
                0.3538985736925515
            ],
            [
                0.15134529147982062,
                0.3438985736925515
            ]
        ],
        "score": 0.9536008238792419,
        "text": "别样本来学习低维空间的投影，以提高分类效果。",
        "type": "text"
    },
    {
        "position": [
            [
                0.18721973094170405,
                0.3486529318541997
            ],
            [
                0.8497757847533632,
                0.3486529318541997
            ],
            [
                0.8597757847533632,
                0.37212361331220284
            ],
            [
                0.18721973094170405,
                0.36212361331220283
            ]
        ],
        "score": 0.9600663185119629,
        "text": "两者的区别主要为PCA注重数据内在结构，LDA注重不同类别间差异最大化。PCA提取主",
        "type": "text"
    },
    {
        "position": [
            [
                0.15358744394618834,
                0.36687797147385104
            ],
            [
                0.8486547085201793,
                0.36687797147385104
            ],
            [
                0.8586547085201793,
                0.3903486529318542
            ],
            [
                0.15358744394618834,
                0.3803486529318542
            ]
        ],
        "score": 0.977806806564331,
        "text": "成分来解释最大变异，LDA学习能最大限度区分不同类别的投影向量。PCA广泛用于降维和可",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.384310618066561
            ],
            [
                0.6625560538116592,
                0.384310618066561
            ],
            [
                0.6725560538116592,
                0.4077812995245642
            ],
            [
                0.15134529147982062,
                0.3977812995245642
            ]
        ],
        "score": 0.9135777950286865,
        "text": "视化，LDA主要用于降维后再做分类任务，如文本分类、图像分类等，",
        "type": "text"
    },
    {
        "position": [
            [
                0.3531390134529148,
                0.42709984152139463
            ],
            [
                0.649103139013453,
                0.42709984152139463
            ],
            [
                0.659103139013453,
                0.4505705229793978
            ],
            [
                0.3531390134529148,
                0.4405705229793978
            ]
        ],
        "score": 0.9336179494857788,
        "text": "表5观测数据实验与正常对照的比较",
        "type": "text"
    },
    {
        "position": [
            [
                0.1860986547085202,
                0.6814580031695721
            ],
            [
                0.8363228699551569,
                0.6814580031695721
            ],
            [
                0.8463228699551569,
                0.7049286846275753
            ],
            [
                0.1860986547085202,
                0.6949286846275753
            ]
        ],
        "score": 0.9498278498649597,
        "text": "如表5，当MMPI中的疑病、抑郁、瘾病、精神病态、男性女性化、妄想、精神衰弱、",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.6996830427892234
            ],
            [
                0.8497757847533632,
                0.6996830427892234
            ],
            [
                0.8597757847533632,
                0.7231537242472267
            ],
            [
                0.15134529147982062,
                0.7131537242472267
            ]
        ],
        "score": 0.9375461339950562,
        "text": "精神分裂症、社会内向的量表得分高于正常水平且疑病、抑郁、瘾症（两点编码类型）、精",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.7187004754358162
            ],
            [
                0.6681614349775785,
                0.7187004754358162
            ],
            [
                0.6781614349775785,
                0.7421711568938193
            ],
            [
                0.15134529147982062,
                0.7321711568938193
            ]
        ],
        "score": 0.9505599737167358,
        "text": "神衰弱显著高于常模60，则选用Y-BOCS进行进一步精神状态评估。",
        "type": "text"
    },
    {
        "position": [
            [
                0.18497757847533633,
                0.7353407290015848
            ],
            [
                0.8486547085201793,
                0.7353407290015848
            ],
            [
                0.8586547085201793,
                0.758811410459588
            ],
            [
                0.18497757847533633,
                0.748811410459588
            ]
        ],
        "score": 0.9712480306625366,
        "text": "F范数是矩阵的一种范数，也称为矩阵的欧几里德范数。F范数可以用来度量矩阵的大",
        "type": "text"
    },
    {
        "position": [
            [
                0.15134529147982062,
                0.7559429477020603
            ],
            [
                0.7724215246636771,
                0.7559429477020603
            ],
            [
                0.7824215246636771,
                0.7794136291600634
            ],
            [
                0.15134529147982062,
                0.7694136291600634
            ]
        ],
        "score": 0.9471923112869263,
        "text": "小或者复杂度，还可以用于矩阵近似和矩阵压缩等问题中。F范数计算公式如下：",
        "type": "text"
    },
    {
        "position": [
            [
                0.1860986547085202,
                0.8114104595879557
            ],
            [
                0.8408071748878924,
                0.8114104595879557
            ],
            [
                0.8508071748878924,
                0.8348811410459588
            ],
            [
                0.1860986547085202,
                0.8248811410459588
            ]
        ],
        "score": 0.9494693279266357,
        "text": "F范数常用于矩阵的正则化、优化问题以及矩阵的相似性度量等方面。在机器学习中，",
        "type": "text"
    },
    {
        "position": [
            [
                0.15022421524663676,
                0.8288431061806656
            ],
            [
                0.8486547085201793,
                0.8288431061806656
            ],
            [
                0.8586547085201793,
                0.8523137876386688
            ],
            [
                0.15022421524663676,
                0.8423137876386688
            ]
        ],
        "score": 0.9594961404800415,
        "text": "F范数常被用作损失函数的一部分，用于衡量模型预测值与真实值之间的差异。此外，F范",
        "type": "text"
    },
    {
        "position": [
            [
                0.15022421524663676,
                0.8486529318541997
            ],
            [
                0.5650224215246636,
                0.8486529318541997
            ],
            [
                0.5750224215246637,
                0.8721236133122029
            ],
            [
                0.15022421524663676,
                0.8621236133122029
            ]
        ],
        "score": 0.9199503064155579,
        "text": "数还经常出现在矩阵分解、矩阵压缩等领域的问题中。",
        "type": "text"
    }
]